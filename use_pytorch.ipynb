{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "from torch import optim\n", "from torch.autograd import Variable\n", "from torch.utils.data import DataLoader\n", "from torchvision import datasets, transforms"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from torch import nn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Simple_Net(nn.Module):\n", "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n", "        super(Simple_Net, self).__init__()\n", "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1), nn.BatchNorm1d(n_hidden_1), nn.ReLU(True))\n", "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2), nn.BatchNorm1d(n_hidden_2), nn.ReLU(True))\n", "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))\n", "    def forward(self, x):\n", "        x = self.layer1(x)\n", "        x = self.layer2(x)\n", "        x = self.layer3(x)\n", "        return x"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["BATCH_SIZE = 64 #change default value\n", "NUM_EPOCHS = 20 #change default value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data_tf = transforms.Compose(\n", "    [transforms.ToTensor(),\n", "     transforms.Normalize([0.5], [0.5])])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dataset = datasets.MNIST(root='./data', train=True, transform=data_tf, download=True)\n", "test_dataset = datasets.MNIST(root='./data', train=False, transform=data_tf, download=False)\n", "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n", "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = Simple_Net(28 * 28, 300, 100, 10)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.CrossEntropyLoss()\n", "optimizer = optim.SGD(model.parameters(), lr=0.02)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["epoch = 0\n", "for epoch in range(NUM_EPOCHS):\n", "    for data in train_loader:\n", "        img, label = data\n", "        img = img.view(img.size(0), -1)\n", "        img = Variable(img)\n", "        label = Variable(label)\n", "        out = model(img)\n", "        loss = criterion(out, label)\n", "        optimizer.zero_grad()\n", "        loss.backward()\n", "        optimizer.step()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.eval()\n", "train_acc = 0\n", "test_acc = 0\n", "for data in train_loader:\n", "    img, label = data\n", "    img = img.view(img.size(0), -1)\n", "    out = model(img)\n", "    _, pred = torch.max(out, 1)\n", "    num_correct = (pred == label).sum()\n", "    train_acc += num_correct.item()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for data in test_loader:\n", "    img, label = data\n", "    img = img.view(img.size(0), -1)\n", "    out = model(img)\n", "    _, pred = torch.max(out, 1)\n", "    num_correct = (pred == label).sum()\n", "    test_acc += num_correct.item()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(' train_acc: {:.6f},test_acc: {:.6f}'.format(\n", "    train_acc / (len(train_dataset)),test_acc / (len(test_dataset))\n", "))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}